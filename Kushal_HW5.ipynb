{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIxAU6f3S-MI"
      },
      "source": [
        "# <Font color = 'pickle'>**Load Libraries/Install Software**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:05.950717Z",
          "iopub.status.busy": "2022-10-24T09:22:05.950028Z",
          "iopub.status.idle": "2022-10-24T09:22:05.976035Z",
          "shell.execute_reply": "2022-10-24T09:22:05.975507Z",
          "shell.execute_reply.started": "2022-10-24T09:22:05.950700Z"
        },
        "id": "silZTZDXNSGU"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:05.977041Z",
          "iopub.status.busy": "2022-10-24T09:22:05.976895Z",
          "iopub.status.idle": "2022-10-24T09:22:06.003745Z",
          "shell.execute_reply": "2022-10-24T09:22:06.003149Z",
          "shell.execute_reply.started": "2022-10-24T09:22:05.977027Z"
        },
        "id": "-h5a-vtFb738",
        "outputId": "9918604e-fdcd-4e44-dcc3-5aca9977d6c2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab')\n",
        "else:\n",
        "  print('Not running on CoLab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.004907Z",
          "iopub.status.busy": "2022-10-24T09:22:06.004631Z",
          "iopub.status.idle": "2022-10-24T09:22:06.032137Z",
          "shell.execute_reply": "2022-10-24T09:22:06.031648Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.004864Z"
        },
        "id": "q4OpOEo0QktF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Install wandb and update it to the latest version\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install wandb --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.033258Z",
          "iopub.status.busy": "2022-10-24T09:22:06.033113Z",
          "iopub.status.idle": "2022-10-24T09:22:06.057829Z",
          "shell.execute_reply": "2022-10-24T09:22:06.057305Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.033244Z"
        },
        "id": "m7C0tvyKoy6f",
        "outputId": "7d1704ac-2884-4b20-abb1-03a3953ceaf0",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.058551Z",
          "iopub.status.busy": "2022-10-24T09:22:06.058401Z",
          "iopub.status.idle": "2022-10-24T09:22:06.083291Z",
          "shell.execute_reply": "2022-10-24T09:22:06.082816Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.058538Z"
        },
        "id": "TqYqOtp5yluv",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.vocab import  vocab\n",
        "\n",
        "import random\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from collections import Counter\n",
        "from types import SimpleNamespace\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.108098Z",
          "iopub.status.busy": "2022-10-24T09:22:06.107923Z",
          "iopub.status.idle": "2022-10-24T09:22:06.134044Z",
          "shell.execute_reply": "2022-10-24T09:22:06.133601Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.108084Z"
        },
        "id": "vsr_hAq78XFz",
        "outputId": "e276cdf6-12c4-4011-d3ad-adcc488640e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkushal07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Login to W&B\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.134555Z",
          "iopub.status.busy": "2022-10-24T09:22:06.134427Z",
          "iopub.status.idle": "2022-10-24T09:22:06.160029Z",
          "shell.execute_reply": "2022-10-24T09:22:06.159623Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.134542Z"
        },
        "id": "zd6c5IGa_iUl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is the path where we will downlaod and save data\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  base_folder = Path('/content/drive/MyDrive/NLP')\n",
        "else:\n",
        "  base_folder = Path('/home/harpreet/Insync/google_drive_shaannoor/data')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.160646Z",
          "iopub.status.busy": "2022-10-24T09:22:06.160510Z",
          "iopub.status.idle": "2022-10-24T09:22:06.184362Z",
          "shell.execute_reply": "2022-10-24T09:22:06.184015Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.160633Z"
        },
        "id": "Z0yKILuteTDE"
      },
      "outputs": [],
      "source": [
        "data_folder = base_folder/'datasets/'\n",
        "model_folder = base_folder/'models/'\n",
        "custom_functions = base_folder/'custom-functions'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.185912Z",
          "iopub.status.busy": "2022-10-24T09:22:06.185778Z",
          "iopub.status.idle": "2022-10-24T09:22:06.209147Z",
          "shell.execute_reply": "2022-10-24T09:22:06.208793Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.185899Z"
        },
        "id": "1i9tdWEkOha8"
      },
      "outputs": [],
      "source": [
        "sys.path.append(str(custom_functions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.209759Z",
          "iopub.status.busy": "2022-10-24T09:22:06.209628Z",
          "iopub.status.idle": "2022-10-24T09:22:06.234346Z",
          "shell.execute_reply": "2022-10-24T09:22:06.233972Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.209746Z"
        },
        "id": "m8C6e11FOiEX",
        "outputId": "a143418d-44dd-43b3-8077-0964a078ab94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/drive/MyDrive/NLP/custom-functions']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sys.path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17xctemopjdA"
      },
      "source": [
        "# <Font color = 'pickle'>**Stack Exchange Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.258687Z",
          "iopub.status.busy": "2022-10-24T09:22:06.258444Z",
          "iopub.status.idle": "2022-10-24T09:22:06.284167Z",
          "shell.execute_reply": "2022-10-24T09:22:06.283743Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.258672Z"
        },
        "id": "2f94n6S-6YCO"
      },
      "outputs": [],
      "source": [
        "# location of train and test files\n",
        "data_file = data_folder /'multiclass_hw_cleaned.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.284889Z",
          "iopub.status.busy": "2022-10-24T09:22:06.284716Z",
          "iopub.status.idle": "2022-10-24T09:22:06.653127Z",
          "shell.execute_reply": "2022-10-24T09:22:06.652721Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.284876Z"
        },
        "id": "5ggR-K3o6fhY"
      },
      "outputs": [],
      "source": [
        "# creating Pandas Dataframe\n",
        "#train_data = pd.read_csv(data_file, index_col=0)\n",
        "train_data=pd.read_csv(\"/content/drive/MyDrive/multiclass_hw_cleaned.csv\",index_col=0)\n",
        "train_data=train_data[['cleaned_text','Tag_Number_final']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.653776Z",
          "iopub.status.busy": "2022-10-24T09:22:06.653641Z",
          "iopub.status.idle": "2022-10-24T09:22:06.679384Z",
          "shell.execute_reply": "2022-10-24T09:22:06.678956Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.653763Z"
        },
        "id": "RXYsyw4r7OGb",
        "outputId": "5606a621-e812-4d88-d26c-2265419e2da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training data set is : (188878, 2)\n"
          ]
        }
      ],
      "source": [
        "# print shape of the datasets\n",
        "print(f'Shape of Training data set is : {train_data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.680252Z",
          "iopub.status.busy": "2022-10-24T09:22:06.680068Z",
          "iopub.status.idle": "2022-10-24T09:22:06.707850Z",
          "shell.execute_reply": "2022-10-24T09:22:06.707345Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.680225Z"
        },
        "id": "ETuO1KJp7R8W",
        "outputId": "a21cb07f-660e-4ce0-fc9b-138d990db7ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        cleaned_text  Tag_Number_final\n",
              "0  detail disclosure indicator uibutton simple wa...                 8\n",
              "1  hello world fail emulator follow hello world t...                 4\n",
              "2  jshint throw possible strict violation line tr...                 3\n",
              "3  programmatically bound column invisible try da...                 9\n",
              "4  edittext get focus soft keyboard android home ...                 4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46e94c33-72c4-43cd-b38b-7a9353ba9e61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>Tag_Number_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>detail disclosure indicator uibutton simple wa...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hello world fail emulator follow hello world t...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jshint throw possible strict violation line tr...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>programmatically bound column invisible try da...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>edittext get focus soft keyboard android home ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46e94c33-72c4-43cd-b38b-7a9353ba9e61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46e94c33-72c4-43cd-b38b-7a9353ba9e61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46e94c33-72c4-43cd-b38b-7a9353ba9e61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_data.head()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTrbf15aROgj"
      },
      "source": [
        "## <Font color = 'pickle'>**Create Train/Test/Valid Split**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.708539Z",
          "iopub.status.busy": "2022-10-24T09:22:06.708395Z",
          "iopub.status.idle": "2022-10-24T09:22:06.733452Z",
          "shell.execute_reply": "2022-10-24T09:22:06.733008Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.708525Z"
        },
        "id": "9RFTtWvX7Vwr"
      },
      "outputs": [],
      "source": [
        "X, y = train_data['cleaned_text'].values, train_data['Tag_Number_final'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:06.734158Z",
          "iopub.status.busy": "2022-10-24T09:22:06.734012Z",
          "iopub.status.idle": "2022-10-24T09:22:06.765176Z",
          "shell.execute_reply": "2022-10-24T09:22:06.764742Z",
          "shell.execute_reply.started": "2022-10-24T09:22:06.734144Z"
        },
        "id": "a8sZ605P7mON"
      },
      "outputs": [],
      "source": [
        "# In the first step we will split the data in training and remaining dataset\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8, random_state=42)\n",
        "\n",
        "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
        "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
        "test_size = 0.5\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTIKaTsTgvYu"
      },
      "source": [
        "## <Font color = 'pickle'>**Custom Dataset Class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:07.037149Z",
          "iopub.status.busy": "2022-10-24T09:22:07.036975Z",
          "iopub.status.idle": "2022-10-24T09:22:07.063057Z",
          "shell.execute_reply": "2022-10-24T09:22:07.062578Z",
          "shell.execute_reply.started": "2022-10-24T09:22:07.037135Z"
        },
        "id": "kul5dyeM2d4k"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"STACK_EXCHANGE dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = np.array(X)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        text = self.X[idx]\n",
        "        labels = self.y[idx]\n",
        "        sample = (text, labels)\n",
        "        \n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:07.063940Z",
          "iopub.status.busy": "2022-10-24T09:22:07.063802Z",
          "iopub.status.idle": "2022-10-24T09:22:07.471457Z",
          "shell.execute_reply": "2022-10-24T09:22:07.470796Z",
          "shell.execute_reply.started": "2022-10-24T09:22:07.063927Z"
        },
        "id": "R1mKoKSlAxAq"
      },
      "outputs": [],
      "source": [
        "trainset = CustomDataset(X_train, y_train)\n",
        "validset = CustomDataset(X_valid, y_valid)\n",
        "testset = CustomDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEVe7eGtY7U"
      },
      "source": [
        "## <Font color = 'pickle'>**Create Vocab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:07.475835Z",
          "iopub.status.busy": "2022-10-24T09:22:07.475552Z",
          "iopub.status.idle": "2022-10-24T09:22:07.505585Z",
          "shell.execute_reply": "2022-10-24T09:22:07.505110Z",
          "shell.execute_reply.started": "2022-10-24T09:22:07.475808Z"
        },
        "id": "LRLHO-M1to6q"
      },
      "outputs": [],
      "source": [
        "def create_vocab(dataset, min_freq):\n",
        "  counter = Counter()\n",
        "  for (text, _) in dataset:\n",
        "    counter.update(str(text).split())\n",
        "  my_vocab = vocab(counter, min_freq=min_freq)\n",
        "  my_vocab.insert_token('<unk>', 0)\n",
        "  my_vocab.set_default_index(0)\n",
        "  return my_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:07.506294Z",
          "iopub.status.busy": "2022-10-24T09:22:07.506154Z",
          "iopub.status.idle": "2022-10-24T09:22:08.211189Z",
          "shell.execute_reply": "2022-10-24T09:22:08.210609Z",
          "shell.execute_reply.started": "2022-10-24T09:22:07.506280Z"
        },
        "id": "wNUi_aNctkAo"
      },
      "outputs": [],
      "source": [
        "stack_vocab = create_vocab(trainset, min_freq = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.211908Z",
          "iopub.status.busy": "2022-10-24T09:22:08.211772Z",
          "iopub.status.idle": "2022-10-24T09:22:08.239663Z",
          "shell.execute_reply": "2022-10-24T09:22:08.239191Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.211894Z"
        },
        "id": "ask8H1QJJMZK",
        "outputId": "206faed5-1ad5-4eb0-c379-9d44e1e82607"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84078"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(stack_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.240488Z",
          "iopub.status.busy": "2022-10-24T09:22:08.240291Z",
          "iopub.status.idle": "2022-10-24T09:22:08.269589Z",
          "shell.execute_reply": "2022-10-24T09:22:08.268970Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.240474Z"
        },
        "id": "eyaeFqCsuRTQ",
        "outputId": "285a92b5-4f79-4f11-d48d-7b7a63cc5395",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', 'fail', 'opening', 'require', 'error']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "stack_vocab.get_itos()[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.270357Z",
          "iopub.status.busy": "2022-10-24T09:22:08.270178Z",
          "iopub.status.idle": "2022-10-24T09:22:08.296058Z",
          "shell.execute_reply": "2022-10-24T09:22:08.295670Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.270327Z"
        },
        "id": "WDMu8-JOujxY",
        "outputId": "f253e3b7-271b-4c97-ad64-b2d882ac03b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "stack_vocab['Validate python Code on']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojvSMWR5u-LU"
      },
      "source": [
        "## <Font color = 'pickle'>**Collate_fn for Data Loaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.296819Z",
          "iopub.status.busy": "2022-10-24T09:22:08.296636Z",
          "iopub.status.idle": "2022-10-24T09:22:08.322287Z",
          "shell.execute_reply": "2022-10-24T09:22:08.321891Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.296805Z"
        },
        "id": "cdBKJlVmvB-9"
      },
      "outputs": [],
      "source": [
        "# Creating a lambda function objects that will be used to get the indices of words from vocab\n",
        "text_pipeline = lambda x: [stack_vocab[token] for token in str(x).split()]\n",
        "label_pipeline = lambda x: int(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.323133Z",
          "iopub.status.busy": "2022-10-24T09:22:08.322814Z",
          "iopub.status.idle": "2022-10-24T09:22:08.349717Z",
          "shell.execute_reply": "2022-10-24T09:22:08.349148Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.323120Z"
        },
        "id": "cL1TZVthvIT2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We know that input to the embedding layers are indices of words from the vocab.\n",
        "The collate_batch() accepts batch of data and gets the indices of text from vocab and returns the same\n",
        "We will include this collate_batch() in collat_fn attribute of DataLoader.\n",
        "So it will create a batch of data containing indices of words and corresponding labels.\n",
        "But for EmbeddingBag we need one more extra parameter, that is offset.\n",
        "offsets determines the starting index position of each bag (sequence) in input.\n",
        "'''\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_text, _label) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return text_list, label_list, offsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5PslDp5R7Ff"
      },
      "source": [
        "## <Font color = 'pickle'>**Check Data Loaders**\n",
        "\n",
        "Let us check if our collate function is working by creating a dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.350505Z",
          "iopub.status.busy": "2022-10-24T09:22:08.350358Z",
          "iopub.status.idle": "2022-10-24T09:22:08.376028Z",
          "shell.execute_reply": "2022-10-24T09:22:08.375584Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.350491Z"
        },
        "id": "4ltYqq5e4NLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41dd8b09-1ef6-4a07-bc58-7cc5274cbf1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "batch_size=2\n",
        "check_loader= torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True,\n",
        "                                        collate_fn=collate_batch,\n",
        "                                        num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.376710Z",
          "iopub.status.busy": "2022-10-24T09:22:08.376572Z",
          "iopub.status.idle": "2022-10-24T09:22:08.611006Z",
          "shell.execute_reply": "2022-10-24T09:22:08.610435Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.376696Z"
        },
        "id": "logKAfqD4SXB",
        "outputId": "e5555bd3-a063-489a-ecb0-7691bab5b7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 1]) tensor([    0,   795,     0,   147,   789,     0,   795,   266,  1962,     0,\n",
            "           27,   542,   146,  2492,  2021,   105,  2172,  2492,    22,     0,\n",
            "           30,  1040,   311,   216,   235,    76,   235,    78,    76,   557,\n",
            "           78,    76,  1170,    78,   274, 14303,    78,    76,   564,    78,\n",
            "           76,   380,    78,   753,    85,  2270,    76,   565,    78,    76,\n",
            "          566,    78,    22,     0,  1159,  7023,  6010,     0,   116,     0,\n",
            "         6010,     0,   116,  1159,     0,    27,     0,   238,   245,   787,\n",
            "         4517,  3153,   155,   198,   235,    26,     0,     4,  4517,  3153,\n",
            "          155,   147,   198,   235,    26,   432, 61413,    38,  1256,   242,\n",
            "         1257,   765,    38,  1256,   242,  1257, 14843,   283,   283,  1233,\n",
            "          283,   782,   283,   816,   283,   792,   283,  2083,   336,    22,\n",
            "         1270,   789,   782,   336,   542,  7014,   795,   336,   797,   798,\n",
            "          799,   800,  7928,   542, 24219,    30, 24219,    30,  8214,     0,\n",
            "         2083,  2084,   151,  8214,   189, 16518,  2083,  2084, 24219,    30,\n",
            "          224,   224,    30,   374,     0,  8214,     0,  2083,  2084,  1846,\n",
            "         1231,    30, 34961,  8214,   189, 19486,  2083,  2084,  1343,  3473,\n",
            "           30,   374,  1353,  7013,  8214,   189, 21984,  2083,  2084,   542,\n",
            "           15,  8214,     0,  2083,  2084,    15,    30,     0,     0,  8214,\n",
            "            0,  2083,  2084,  2656,   809, 29576,   792,  9650,  8851,     0,\n",
            "         5968,     0,   367,    78,    78,    78,   367,  1361,  8214,   309,\n",
            "           30,   367,  1361,   367,   367, 25991,  2083,  2084, 37657,  8214,\n",
            "          189, 44080,  2083,  2084]) tensor([ 0, 70])\n"
          ]
        }
      ],
      "source": [
        "for text, label, offsets in check_loader:\n",
        "  print(label, text, offsets)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ60WJKlg3bQ"
      },
      "source": [
        "# <font color = 'pickle'> **Functions to implement NN Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLIXu5RaylkZ"
      },
      "source": [
        "## <Font color = 'pickle'>**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.612148Z",
          "iopub.status.busy": "2022-10-24T09:22:08.611902Z",
          "iopub.status.idle": "2022-10-24T09:22:08.644739Z",
          "shell.execute_reply": "2022-10-24T09:22:08.644207Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.612127Z"
        },
        "id": "LNJY8GBipO2q",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class MLPCustom(nn.Module):\n",
        "  def __init__(self, embed_dim, vocab_size, hidden_dim1, hidden_dim2, output_dim, non_linearity):\n",
        "\n",
        "    super().__init__()    \n",
        "    self.hidden_dim1 = hidden_dim1\n",
        "    self.hidden_dim2 = hidden_dim2\n",
        "    self.output_dim = output_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "    self.non_linearity = non_linearity\n",
        "\n",
        "    \n",
        "    # embedding_layer\n",
        "    self.embedding = nn.EmbeddingBag(self.vocab_size, self.embed_dim)\n",
        "\n",
        "    # hidden layer1\n",
        "    self.hidden_layer1 = nn.Linear(self.embed_dim, self.hidden_dim1)\n",
        "\n",
        "    # dropout layer 1\n",
        "    self.drop1 = nn.Dropout(p= 0.5)\n",
        "\n",
        "    # batch layer norm 1\n",
        "    self.batchnorm1 = nn.BatchNorm1d(num_features=self.hidden_dim1)\n",
        "\n",
        "    # hideen layer2\n",
        "    self.hidden_layer2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "    \n",
        "    # dropout layer 2\n",
        "    self.drop2 = nn.Dropout(p= 0.5)\n",
        "\n",
        "    # batch layer norm 2    \n",
        "    self.batchnorm2 = nn.BatchNorm1d(num_features=self.hidden_dim2)\n",
        "    \n",
        "    # output layer\n",
        "    self.output_layer = nn.Linear(self.hidden_dim2, self.output_dim)\n",
        "\n",
        "    # nonlinearity\n",
        "\n",
        "\n",
        "  def forward(self, input_, offsets):\n",
        "    embed_out = self.embedding(input_, offsets) # batchsize, embedding_dim\n",
        "\n",
        "    hout1 = self.non_linearity(self.hidden_layer1(embed_out)) # batchsize, hidden_dim1\n",
        "    hout1 = self.batchnorm1(hout1)\n",
        "    hout1 = self.drop1(hout1)\n",
        "    \n",
        "    hout2 = self.non_linearity(self.hidden_layer2(hout1)) # batchsize, hidden_dim2\n",
        "    hout2 = self.batchnorm2(hout2)\n",
        "    hout2 = self.drop2(hout2)\n",
        "    \n",
        "    ypred = self.output_layer(hout2) # batchsize, hidden_dim2\n",
        "    \n",
        "    # Note : We do not need to apply softmax as we will be using nn.CrossEntropy Loss\n",
        "\n",
        "    return ypred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqI_o6qwy6lb"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Training  Loops**\n",
        "\n",
        "**Model Training** involves five steps: \n",
        "\n",
        "- Step 0: Randomly initialize parameters / weights\n",
        "- Step 1: Compute model's predictions - forward pass\n",
        "- Step 2: Compute loss\n",
        "- Step 3: Compute the gradients\n",
        "- Step 4: Update the parameters\n",
        "- Step 5: Repeat steps 1 - 4\n",
        "\n",
        "Model training is repeating this process over and over, for many **epochs**.\n",
        "\n",
        "We will specify number of ***epochs*** and during each epoch we will iterate over the complete dataset and will keep on updating the parameters.\n",
        "\n",
        "***Learning rate*** and ***epochs*** are known as hyperparameters. We have to adjust the values of these two based on validation dataset.\n",
        "\n",
        "We will now create functions for step 1 to 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.645736Z",
          "iopub.status.busy": "2022-10-24T09:22:08.645544Z",
          "iopub.status.idle": "2022-10-24T09:22:08.674651Z",
          "shell.execute_reply": "2022-10-24T09:22:08.674116Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.645717Z"
        },
        "id": "Pv4x22lZMn5p",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(train_loader, loss_function, model, optimizer, grad_clipping, max_norm, log_batch, log_interval):\n",
        "\n",
        "  # Training Loop \n",
        "\n",
        "  # initilalize variables as global\n",
        "  # these counts will be updated every epoch\n",
        "  global batch_ct_train\n",
        "\n",
        "  # Initialize train_loss at the he start of the epoch\n",
        "  running_train_loss = 0\n",
        "  running_train_correct = 0\n",
        "  \n",
        "  # put the model in training mode\n",
        "\n",
        "  model.train()\n",
        "  # Iterate on batches from the dataset using train_loader\n",
        "  for input_, targets, offsets in train_loader:\n",
        "    \n",
        "    # move inputs and outputs to GPUs\n",
        "    input_ = input_.to(device)\n",
        "    targets = targets.to(device)\n",
        "    offsets = offsets.to(device)\n",
        "\n",
        "\n",
        "    # Step 1: Forward Pass: Compute model's predictions \n",
        "    output = model(input_, offsets)\n",
        "    \n",
        "    # Step 2: Compute loss\n",
        "    loss = loss_function(output, targets)\n",
        "\n",
        "    # Correct prediction\n",
        "    y_pred = torch.argmax(output, dim = 1)\n",
        "    correct = torch.sum(y_pred == targets)\n",
        "\n",
        "    batch_ct_train += 1\n",
        "\n",
        "    # Step 3: Backward pass -Compute the gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient Clipping\n",
        "    if grad_clipping:\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm, norm_type=2)\n",
        "\n",
        "    # Step 4: Update the parameters\n",
        "    optimizer.step()\n",
        "          \n",
        "    # Add train loss of a batch \n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "    # Add Corect counts of a batch\n",
        "    running_train_correct += correct\n",
        "\n",
        "    # log batch loss and accuracy\n",
        "    if log_batch:\n",
        "      if ((batch_ct_train + 1) % log_interval) == 0:\n",
        "        wandb.log({f\"Train Batch Loss  :\": loss})\n",
        "        wandb.log({f\"Train Batch Acc :\": correct/len(targets)})\n",
        "\n",
        "  \n",
        "  # Calculate mean train loss for the whole dataset for a particular epoch\n",
        "  train_loss = running_train_loss/len(train_loader)\n",
        "\n",
        "  # Calculate accuracy for the whole dataset for a particular epoch\n",
        "  train_acc = running_train_correct/len(train_loader.dataset)\n",
        "  \n",
        "\n",
        "  return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLm-GI5bW2V"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Validation Loops**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.675883Z",
          "iopub.status.busy": "2022-10-24T09:22:08.675433Z",
          "iopub.status.idle": "2022-10-24T09:22:08.703605Z",
          "shell.execute_reply": "2022-10-24T09:22:08.703113Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.675864Z"
        },
        "id": "pHP1WKDessiI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def validate(valid_loader, loss_function, model, log_batch, log_interval):\n",
        "\n",
        "  # initilalize variables as global\n",
        "  # these counts will be updated every epoch\n",
        "  global batch_ct_valid\n",
        "\n",
        "  # Validation/Test loop\n",
        "  # Initialize valid_loss at the he strat of the epoch\n",
        "  running_val_loss = 0\n",
        "  running_val_correct = 0\n",
        "\n",
        "  # put the model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for input_, targets, offsets in valid_loader:\n",
        "\n",
        "      # move inputs and outputs to GPUs\n",
        "      input_ = input_.to(device)\n",
        "      targets = targets.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "\n",
        "      # Step 1: Forward Pass: Compute model's predictions \n",
        "      output = model(input_, offsets)\n",
        "\n",
        "      # Step 2: Compute loss\n",
        "      loss = loss_function(output, targets)\n",
        "\n",
        "      # Correct Predictions\n",
        "      y_pred = torch.argmax(output, dim = 1)\n",
        "      correct = torch.sum(y_pred == targets)\n",
        "\n",
        "      batch_ct_valid += 1\n",
        "\n",
        "      # Add val loss of a batch \n",
        "      running_val_loss += loss.item()\n",
        "\n",
        "      # Add correct count for each batch\n",
        "      running_val_correct += correct\n",
        "\n",
        "      # log batch loss and accuracy\n",
        "      if log_batch:\n",
        "        if ((batch_ct_valid + 1) % log_interval) == 0:\n",
        "          wandb.log({f\"Valid Batch Loss  :\": loss})\n",
        "          wandb.log({f\"Valid Batch Accuracy :\": correct/len(targets)})\n",
        "\n",
        "    # Calculate mean val loss for the whole dataset for a particular epoch\n",
        "    val_loss = running_val_loss/len(valid_loader)\n",
        "\n",
        "    # Calculate accuracy for the whole dataset for a particular epoch\n",
        "    val_acc = running_val_correct/len(valid_loader.dataset)\n",
        "\n",
        "    # scheduler step\n",
        "    # scheduler.step(valid_loss)\n",
        "    # scheduler.step()\n",
        "    \n",
        "  return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwF70eqE6n_v"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Model Training**\n",
        "    \n",
        "We will now create a function for step 5 of model training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.704977Z",
          "iopub.status.busy": "2022-10-24T09:22:08.704490Z",
          "iopub.status.idle": "2022-10-24T09:22:08.736110Z",
          "shell.execute_reply": "2022-10-24T09:22:08.735492Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.704957Z"
        },
        "id": "KeCKVgg-5FiZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_loop(train_loader, valid_loader, model, optimizer, loss_function, epochs, device, patience, early_stopping,\n",
        "               file_model, save_best_model):\n",
        "    \n",
        "  \"\"\" \n",
        "  Function for training the model and plotting the graph for train & validation loss vs epoch.\n",
        "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n",
        "  Output: final weights, bias and train loss and validation loss for each epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create lists to store train and val loss at each epoch\n",
        "  train_loss_history = []\n",
        "  valid_loss_history = []\n",
        "  train_acc_history = []\n",
        "  valid_acc_history = []\n",
        "\n",
        "  # initialize variables for early stopping\n",
        "\n",
        "  delta = 0\n",
        "  best_score = None\n",
        "  valid_loss_min = np.Inf\n",
        "  counter_early_stop=0\n",
        "  early_stop=False\n",
        "\n",
        "  # Iterate for the given number of epochs\n",
        "  # Step 5: Repeat steps 1 - 4\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    t0 = datetime.now()\n",
        "\n",
        "    # Get train loss and accuracy for one epoch\n",
        "    train_loss, train_acc = train(train_loader, loss_function, model, optimizer, \n",
        "                                  wandb.config.GRAD_CLIPPING, wandb.config.MAX_NORM,\n",
        "                                  wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n",
        "    valid_loss, valid_acc   = validate(valid_loader, loss_function, model, \n",
        "                                       wandb.config.LOG_BATCH, wandb.config.LOG_INTERVAL)\n",
        "\n",
        "    dt = datetime.now() - t0\n",
        "\n",
        "    # Save history of the Losses and accuracy\n",
        "    train_loss_history.append(train_loss)\n",
        "    train_acc_history.append(train_acc)\n",
        "\n",
        "    valid_loss_history.append(valid_loss)\n",
        "    valid_acc_history.append(valid_acc)\n",
        "\n",
        "    # Log the train and valid loss to wandb\n",
        "    wandb.log({f\"Train Loss :\": train_loss, \"epoch\": epoch})\n",
        "    wandb.log({f\"Train Acc :\": train_acc, \"epoch\": epoch})\n",
        "\n",
        "    wandb.log({f\"Valid Loss :\": valid_loss, \"epoch\": epoch})\n",
        "    wandb.log({f\"Valid Acc :\": valid_acc, \"epoch\": epoch})\n",
        "\n",
        "    if early_stopping:\n",
        "      score = -valid_loss\n",
        "      if best_score is None:\n",
        "        best_score=score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      elif score < best_score + delta:\n",
        "        counter_early_stop += 1\n",
        "        print(f'Early stoping counter: {counter_early_stop} out of {patience}')\n",
        "        if counter_early_stop > patience:\n",
        "          early_stop = True\n",
        "\n",
        "\n",
        "      else:\n",
        "        best_score = score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        counter_early_stop=0\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      if early_stop:\n",
        "        print('Early Stopping')\n",
        "        break\n",
        "\n",
        "    elif save_best_model:\n",
        "\n",
        "      score = -valid_loss\n",
        "      if best_score is None:\n",
        "        best_score=score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "      elif score < best_score + delta:\n",
        "        print(f'Validation loss has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model...')\n",
        "      \n",
        "      else:\n",
        "        best_score = score\n",
        "        print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        valid_loss_min = valid_loss\n",
        "        \n",
        "    else:\n",
        "        torch.save(model.state_dict(), file_model)\n",
        "        \n",
        "    \n",
        "    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n",
        "    print(f'Epoch : {epoch+1} / {epochs}')\n",
        "    print(f'Time to complete {epoch+1} is {dt}')\n",
        "    # print(f'Learning rate: {scheduler._last_lr[0]}')\n",
        "    print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n",
        "    print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n",
        "    print()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWCLH47azD6j"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Accuracy and Predictions**\n",
        "\n",
        "Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.737097Z",
          "iopub.status.busy": "2022-10-24T09:22:08.736789Z",
          "iopub.status.idle": "2022-10-24T09:22:08.766610Z",
          "shell.execute_reply": "2022-10-24T09:22:08.766133Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.737077Z"
        },
        "id": "M6KZqsnqQFVu",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_acc_pred(data_loader, model, device):\n",
        "    \n",
        "  \"\"\" \n",
        "  Function to get predictions and accuracy for a given data using estimated model\n",
        "  Input: Data iterator, Final estimated weoights, bias\n",
        "  Output: Prections and Accuracy for given dataset\n",
        "  \"\"\"\n",
        "\n",
        "  # Array to store predicted labels\n",
        "  predictions = torch.Tensor() # empty tensor\n",
        "  predictions = predictions.to(device) # move predictions to GPU\n",
        "\n",
        "  # Array to store actual labels\n",
        "  y = torch.Tensor() # empty tensor\n",
        "  y = y.to(device)\n",
        "\n",
        "  # put the model in evaluation mode\n",
        "  model.eval()\n",
        "  \n",
        "  # Iterate over batches from data iterator\n",
        "  with torch.no_grad():\n",
        "    for input_, targets, offsets in data_loader:\n",
        "      \n",
        "      # move inputs and outputs to GPUs\n",
        "      \n",
        "      input_ = input_.to(device)\n",
        "      targets = targets.to(device)\n",
        "      offsets = offsets.to(device)\n",
        "      \n",
        "      # Calculated the predicted labels\n",
        "      output = model(input_, offsets)\n",
        "\n",
        "      # Choose the label with maximum probability\n",
        "      prediction = torch.argmax(output, dim = 1)\n",
        "\n",
        "      # Add the predicted labels to the array\n",
        "      predictions = torch.cat((predictions, prediction)) \n",
        "\n",
        "      # Add the actual labels to the array\n",
        "      y = torch.cat((y, targets)) \n",
        "\n",
        "  # Check for complete dataset if actual and predicted labels are same or not\n",
        "  # Calculate accuracy\n",
        "  acc = (predictions == y).float().mean()\n",
        "\n",
        "  # Return tuple containing predictions and accuracy\n",
        "  return predictions, acc  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nF5iTy_VqdV"
      },
      "source": [
        "# <Font color = 'pickle'>**Meta Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.767546Z",
          "iopub.status.busy": "2022-10-24T09:22:08.767317Z",
          "iopub.status.idle": "2022-10-24T09:22:08.794203Z",
          "shell.execute_reply": "2022-10-24T09:22:08.793600Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.767526Z"
        },
        "id": "TAuG3mxBWHaz"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "hyperparameters = SimpleNamespace(\n",
        "    EMBED_DIM = 300,\n",
        "    VOCAB_SIZE = len(stack_vocab),\n",
        "    OUTPUT_DIM = 10,\n",
        "    HIDDEN_DIM1 = 200,\n",
        "    HIDDEN_DIM2 = 100,\n",
        "    NON_LINEARITY= F.relu,\n",
        "    EPOCHS = 20,\n",
        "    \n",
        "    BATCH_SIZE = 256,\n",
        "    LEARNING_RATE = 0.2,\n",
        "    DATASET=\"Stack_Exchange\",\n",
        "    ARCHITECTUREe=\"Embed_2_hidden_layers\",\n",
        "    LOG_INTERVAL = 25,\n",
        "    LOG_BATCH = True,\n",
        "    FILE_MODEL = base_folder/'stack_2_hidden_layers.pt',\n",
        "    GRAD_CLIPPING = False,\n",
        "    MAX_NORM = 0,\n",
        "    MOMENTUM = 0,\n",
        "    PATIENCE = 5,\n",
        "    EARLY_STOPPING = True,\n",
        "    # SCHEDULER_FACTOR = 0,\n",
        "    # SCHEDULER_PATIENCE = 0,\n",
        "    WEIGHT_DECAY = 0.0,\n",
        "    SAVE_BEST_MODEL = True,\n",
        "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVk_RctgdPRP"
      },
      "source": [
        "# <Font color = 'pickle'>**Data Loaders, Loss Function, Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:08.795239Z",
          "iopub.status.busy": "2022-10-24T09:22:08.794844Z",
          "iopub.status.idle": "2022-10-24T09:22:14.251208Z",
          "shell.execute_reply": "2022-10-24T09:22:14.250750Z",
          "shell.execute_reply.started": "2022-10-24T09:22:08.795219Z"
        },
        "id": "3kCRNDlu-zbE",
        "outputId": "aaeff2b3-164a-4ee3-926f-e8b0887f1e85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221031_031124-18q3ppid</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/kushal07/NLP_complete_example_f22/runs/18q3ppid\" target=\"_blank\">Embed_2_hidden_layers</a></strong> to <a href=\"https://wandb.ai/kushal07/NLP_complete_example_f22\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/kushal07/NLP_complete_example_f22/runs/18q3ppid?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f69b3aff850>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Initialize a new project\n",
        "import random\n",
        "wandb.init(name = 'Embed_2_hidden_layers', project = 'NLP_complete_example_f22', config = hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:14.252001Z",
          "iopub.status.busy": "2022-10-24T09:22:14.251819Z",
          "iopub.status.idle": "2022-10-24T09:22:14.282245Z",
          "shell.execute_reply": "2022-10-24T09:22:14.281781Z",
          "shell.execute_reply.started": "2022-10-24T09:22:14.251986Z"
        },
        "id": "Gnl8vsAN-5Tq",
        "outputId": "c276612e-ee75-4411-fd3a-5d3eea8ba3ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='Embed_2_hidden_layers', BATCH_SIZE=256, DATASET='Stack_Exchange', DEVICE=device(type='cpu'), EARLY_STOPPING=True, EMBED_DIM=300, EPOCHS=20, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/stack_2_hidden_layers.pt'), GRAD_CLIPPING=False, HIDDEN_DIM1=200, HIDDEN_DIM2=100, LEARNING_RATE=0.2, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=<function relu at 0x7f69d2a44f80>, OUTPUT_DIM=10, PATIENCE=5, SAVE_BEST_MODEL=True, VOCAB_SIZE=84078, WEIGHT_DECAY=0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "wandb.config = hyperparameters\n",
        "wandb.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:14.283277Z",
          "iopub.status.busy": "2022-10-24T09:22:14.283050Z",
          "iopub.status.idle": "2022-10-24T09:22:14.433708Z",
          "shell.execute_reply": "2022-10-24T09:22:14.433252Z",
          "shell.execute_reply.started": "2022-10-24T09:22:14.283255Z"
        },
        "id": "fZ6ZoM9WaS_M",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Fix seed value\n",
        "SEED = 2345\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=wandb.config.BATCH_SIZE, shuffle = True, \n",
        "                                           collate_fn=collate_batch, num_workers = 4)\n",
        "valid_loader = torch.utils.data.DataLoader(validset, batch_size=wandb.config.BATCH_SIZE, shuffle = False, \n",
        "                                           collate_fn=collate_batch,  num_workers = 4)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=wandb.config.BATCH_SIZE,   shuffle = False, \n",
        "                                          collate_fn=collate_batch,  num_workers = 4)\n",
        "\n",
        "# cross entropy loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# model \n",
        "model_stack = MLPCustom(wandb.config.EMBED_DIM, \n",
        "                       wandb.config.VOCAB_SIZE, \n",
        "                       wandb.config.HIDDEN_DIM1, \n",
        "                       wandb.config.HIDDEN_DIM2,\n",
        "                       wandb.config.OUTPUT_DIM, \n",
        "                       wandb.config.NON_LINEARITY)\n",
        "\n",
        "model_stack.to(wandb.config.DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "      torch.nn.init.kaiming_normal_(m.weight)\n",
        "      torch.nn.init.zeros_(m.bias)\n",
        "        \n",
        "# apply initialization recursively  to all modules\n",
        "model_stack.apply(init_weights)\n",
        "\n",
        "# Intialize stochiastic gradient descent optimizer\n",
        "optimizer = torch.optim.SGD(model_stack.parameters(), \n",
        "                             lr = wandb.config.LEARNING_RATE, \n",
        "                             weight_decay=wandb.config.WEIGHT_DECAY)\n",
        "\n",
        "wandb.config.OPTIMIZER = optimizer\n",
        "\n",
        "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor= wandb.config.scheduler_factor, \n",
        "#                              patience=wandb.config.scheduler_patience, verbose=True)\n",
        "\n",
        "#scheduler = StepLR(optimizer, gamma=0.4,step_size=1, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:14.434390Z",
          "iopub.status.busy": "2022-10-24T09:22:14.434265Z",
          "iopub.status.idle": "2022-10-24T09:22:14.461486Z",
          "shell.execute_reply": "2022-10-24T09:22:14.461157Z",
          "shell.execute_reply.started": "2022-10-24T09:22:14.434377Z"
        },
        "id": "6etbfbQkm-zv",
        "outputId": "8c4f08b3-a6ff-4516-eaa3-90a827d0fd57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(ARCHITECTUREe='Embed_2_hidden_layers', BATCH_SIZE=256, DATASET='Stack_Exchange', DEVICE=device(type='cpu'), EARLY_STOPPING=True, EMBED_DIM=300, EPOCHS=20, FILE_MODEL=PosixPath('/content/drive/MyDrive/NLP/stack_2_hidden_layers.pt'), GRAD_CLIPPING=False, HIDDEN_DIM1=200, HIDDEN_DIM2=100, LEARNING_RATE=0.2, LOG_BATCH=True, LOG_INTERVAL=25, MAX_NORM=0, MOMENTUM=0, NON_LINEARITY=<function relu at 0x7f69d2a44f80>, OPTIMIZER=SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    foreach: None\n",
              "    lr: 0.2\n",
              "    maximize: False\n",
              "    momentum: 0\n",
              "    nesterov: False\n",
              "    weight_decay: 0.0\n",
              "), OUTPUT_DIM=10, PATIENCE=5, SAVE_BEST_MODEL=True, VOCAB_SIZE=84078, WEIGHT_DECAY=0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "wandb.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffeGh2dcukdK"
      },
      "source": [
        "# <Font color = 'pickle'>**Sanity Check**\n",
        "- Check the loss without any training. For Cross entropy the expected value will be log(number of classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:14.462462Z",
          "iopub.status.busy": "2022-10-24T09:22:14.462136Z",
          "iopub.status.idle": "2022-10-24T09:22:14.705187Z",
          "shell.execute_reply": "2022-10-24T09:22:14.704720Z",
          "shell.execute_reply.started": "2022-10-24T09:22:14.462447Z"
        },
        "id": "p2Gx7jgbumux",
        "outputId": "5e3cb3d1-9aef-44d8-e08d-b453be5d10b9",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual loss: 2.359091281890869\n",
            "Expected Theoretical loss: 0.6931471805599453\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "for input_, targets, offsets in train_loader:\n",
        "  \n",
        "  # move inputs and outputs to GPUs\n",
        "  input_ = input_.to(device)\n",
        "  targets = targets.to(device)\n",
        "  offsets = offsets.to(device)\n",
        "  model_stack.eval()\n",
        "  # Forward pass\n",
        "  output = model_stack(input_, offsets)\n",
        "  loss = loss_function(output, targets)\n",
        "  print(f'Actual loss: {loss}')\n",
        "  break\n",
        "\n",
        "print(f'Expected Theoretical loss: {np.log(2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0_zWk0Ib74K"
      },
      "source": [
        "# <Font color = 'pickle'>**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:14.705958Z",
          "iopub.status.busy": "2022-10-24T09:22:14.705818Z",
          "iopub.status.idle": "2022-10-24T09:22:14.739496Z",
          "shell.execute_reply": "2022-10-24T09:22:14.739130Z",
          "shell.execute_reply.started": "2022-10-24T09:22:14.705944Z"
        },
        "id": "KczRQvKwiH_y",
        "outputId": "e299088d-89b2-4d22-d160-45b053793b18",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7f69b5705190>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "wandb.watch(model_stack, log = 'all', log_freq=25, log_graph=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:22:14.740216Z",
          "iopub.status.busy": "2022-10-24T09:22:14.740051Z",
          "iopub.status.idle": "2022-10-24T09:23:02.024643Z",
          "shell.execute_reply": "2022-10-24T09:23:02.023960Z",
          "shell.execute_reply.started": "2022-10-24T09:22:14.740202Z"
        },
        "id": "LckLb_9bhZDw",
        "outputId": "1efa4e48-9c1d-4339-b888-51f1558cadff",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has decreased (inf --> 0.730517). Saving Model...\n",
            "Epoch : 1 / 20\n",
            "Time to complete 1 is 0:01:27.800849\n",
            "Train Loss:  1.1501 | Train Accuracy:  63.0217%\n",
            "Valid Loss:  0.7305 | Valid Accuracy:  76.8371%\n",
            "\n",
            "Validation loss has decreased (0.730517 --> 0.658811). Saving model...\n",
            "Epoch : 2 / 20\n",
            "Time to complete 2 is 0:01:26.466880\n",
            "Train Loss:  0.8415 | Train Accuracy:  73.3961%\n",
            "Valid Loss:  0.6588 | Valid Accuracy:  78.8119%\n",
            "\n",
            "Validation loss has decreased (0.658811 --> 0.623611). Saving model...\n",
            "Epoch : 3 / 20\n",
            "Time to complete 3 is 0:01:23.853373\n",
            "Train Loss:  0.7690 | Train Accuracy:  75.7727%\n",
            "Valid Loss:  0.6236 | Valid Accuracy:  79.9608%\n",
            "\n",
            "Validation loss has decreased (0.623611 --> 0.598396). Saving model...\n",
            "Epoch : 4 / 20\n",
            "Time to complete 4 is 0:01:30.328596\n",
            "Train Loss:  0.7246 | Train Accuracy:  77.0963%\n",
            "Valid Loss:  0.5984 | Valid Accuracy:  80.4479%\n",
            "\n",
            "Validation loss has decreased (0.598396 --> 0.577236). Saving model...\n",
            "Epoch : 5 / 20\n",
            "Time to complete 5 is 0:01:25.743687\n",
            "Train Loss:  0.6935 | Train Accuracy:  78.2015%\n",
            "Valid Loss:  0.5772 | Valid Accuracy:  81.2209%\n",
            "\n",
            "Validation loss has decreased (0.577236 --> 0.567471). Saving model...\n",
            "Epoch : 6 / 20\n",
            "Time to complete 6 is 0:01:24.699427\n",
            "Train Loss:  0.6677 | Train Accuracy:  79.0645%\n",
            "Valid Loss:  0.5675 | Valid Accuracy:  81.5015%\n",
            "\n",
            "Validation loss has decreased (0.567471 --> 0.548902). Saving model...\n",
            "Epoch : 7 / 20\n",
            "Time to complete 7 is 0:01:22.793082\n",
            "Train Loss:  0.6467 | Train Accuracy:  79.5853%\n",
            "Valid Loss:  0.5489 | Valid Accuracy:  82.1792%\n",
            "\n",
            "Validation loss has decreased (0.548902 --> 0.535778). Saving model...\n",
            "Epoch : 8 / 20\n",
            "Time to complete 8 is 0:01:24.495198\n",
            "Train Loss:  0.6285 | Train Accuracy:  80.1419%\n",
            "Valid Loss:  0.5358 | Valid Accuracy:  82.4280%\n",
            "\n",
            "Validation loss has decreased (0.535778 --> 0.525192). Saving model...\n",
            "Epoch : 9 / 20\n",
            "Time to complete 9 is 0:01:22.421207\n",
            "Train Loss:  0.6128 | Train Accuracy:  80.6025%\n",
            "Valid Loss:  0.5252 | Valid Accuracy:  82.9680%\n",
            "\n",
            "Validation loss has decreased (0.525192 --> 0.518633). Saving model...\n",
            "Epoch : 10 / 20\n",
            "Time to complete 10 is 0:01:25.818922\n",
            "Train Loss:  0.5985 | Train Accuracy:  81.0128%\n",
            "Valid Loss:  0.5186 | Valid Accuracy:  83.0527%\n",
            "\n",
            "Validation loss has decreased (0.518633 --> 0.506762). Saving model...\n",
            "Epoch : 11 / 20\n",
            "Time to complete 11 is 0:01:27.033685\n",
            "Train Loss:  0.5838 | Train Accuracy:  81.5350%\n",
            "Valid Loss:  0.5068 | Valid Accuracy:  83.4551%\n",
            "\n",
            "Validation loss has decreased (0.506762 --> 0.497828). Saving model...\n",
            "Epoch : 12 / 20\n",
            "Time to complete 12 is 0:01:22.817659\n",
            "Train Loss:  0.5717 | Train Accuracy:  81.9890%\n",
            "Valid Loss:  0.4978 | Valid Accuracy:  83.7039%\n",
            "\n",
            "Validation loss has decreased (0.497828 --> 0.496309). Saving model...\n",
            "Epoch : 13 / 20\n",
            "Time to complete 13 is 0:01:25.659989\n",
            "Train Loss:  0.5607 | Train Accuracy:  82.2709%\n",
            "Valid Loss:  0.4963 | Valid Accuracy:  83.6986%\n",
            "\n",
            "Validation loss has decreased (0.496309 --> 0.485652). Saving model...\n",
            "Epoch : 14 / 20\n",
            "Time to complete 14 is 0:01:23.496679\n",
            "Train Loss:  0.5499 | Train Accuracy:  82.6170%\n",
            "Valid Loss:  0.4857 | Valid Accuracy:  84.1010%\n",
            "\n",
            "Validation loss has decreased (0.485652 --> 0.477471). Saving model...\n",
            "Epoch : 15 / 20\n",
            "Time to complete 15 is 0:01:24.101954\n",
            "Train Loss:  0.5425 | Train Accuracy:  82.8023%\n",
            "Valid Loss:  0.4775 | Valid Accuracy:  84.1646%\n",
            "\n",
            "Validation loss has decreased (0.477471 --> 0.468464). Saving model...\n",
            "Epoch : 16 / 20\n",
            "Time to complete 16 is 0:01:25.113078\n",
            "Train Loss:  0.5310 | Train Accuracy:  83.2319%\n",
            "Valid Loss:  0.4685 | Valid Accuracy:  84.4134%\n",
            "\n",
            "Validation loss has decreased (0.468464 --> 0.463234). Saving model...\n",
            "Epoch : 17 / 20\n",
            "Time to complete 17 is 0:01:26.962700\n",
            "Train Loss:  0.5217 | Train Accuracy:  83.4794%\n",
            "Valid Loss:  0.4632 | Valid Accuracy:  84.6993%\n",
            "\n",
            "Validation loss has decreased (0.463234 --> 0.461740). Saving model...\n",
            "Epoch : 18 / 20\n",
            "Time to complete 18 is 0:01:23.618150\n",
            "Train Loss:  0.5154 | Train Accuracy:  83.6084%\n",
            "Valid Loss:  0.4617 | Valid Accuracy:  84.9111%\n",
            "\n",
            "Validation loss has decreased (0.461740 --> 0.454822). Saving model...\n",
            "Epoch : 19 / 20\n",
            "Time to complete 19 is 0:01:28.234264\n",
            "Train Loss:  0.5078 | Train Accuracy:  83.8679%\n",
            "Valid Loss:  0.4548 | Valid Accuracy:  85.1122%\n",
            "\n",
            "Validation loss has decreased (0.454822 --> 0.453444). Saving model...\n",
            "Epoch : 20 / 20\n",
            "Time to complete 20 is 0:01:24.969408\n",
            "Train Loss:  0.5008 | Train Accuracy:  84.1101%\n",
            "Valid Loss:  0.4534 | Valid Accuracy:  85.1122%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# See live graphs in the notebook.\n",
        "#%%wandb \n",
        "batch_ct_train, batch_ct_valid = 0, 0\n",
        "train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_loop(train_loader, \n",
        "                                                                                          valid_loader, \n",
        "                                                                                          model_stack, \n",
        "                                                                                          optimizer,\n",
        "                                                                                          loss_function, \n",
        "                                                                                          wandb.config.EPOCHS, \n",
        "                                                                                          wandb.config.DEVICE,\n",
        "                                                                                          wandb.config.PATIENCE, \n",
        "                                                                                          wandb.config.EARLY_STOPPING,\n",
        "                                                                                          wandb.config.FILE_MODEL,wandb.config.SAVE_BEST_MODEL\n",
        "                                                                                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Cj1f2Qb74K"
      },
      "source": [
        "# <Font color = 'pickle'>**Get Accuracy, Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:02.025656Z",
          "iopub.status.busy": "2022-10-24T09:23:02.025452Z",
          "iopub.status.idle": "2022-10-24T09:23:02.064399Z",
          "shell.execute_reply": "2022-10-24T09:23:02.064004Z",
          "shell.execute_reply.started": "2022-10-24T09:23:02.025640Z"
        },
        "id": "dZQF1CbgKEKd",
        "outputId": "680b6c84-003e-42f7-93dc-bc869b7b91cc",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:02.065298Z",
          "iopub.status.busy": "2022-10-24T09:23:02.065102Z",
          "iopub.status.idle": "2022-10-24T09:23:02.180386Z",
          "shell.execute_reply": "2022-10-24T09:23:02.179940Z",
          "shell.execute_reply.started": "2022-10-24T09:23:02.065282Z"
        },
        "id": "yw7GhoZuRdIO",
        "outputId": "95cf6818-d4eb-4c95-fe79-69e9d8583a61",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model_nn = MLPCustom(wandb.config.EMBED_DIM, wandb.config.VOCAB_SIZE, wandb.config.HIDDEN_DIM1, wandb.config.HIDDEN_DIM2, \n",
        "                  wandb.config.OUTPUT_DIM, wandb.config.NON_LINEARITY)\n",
        "model_nn.to(device)\n",
        "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:02.181062Z",
          "iopub.status.busy": "2022-10-24T09:23:02.180903Z",
          "iopub.status.idle": "2022-10-24T09:23:04.130737Z",
          "shell.execute_reply": "2022-10-24T09:23:04.130200Z",
          "shell.execute_reply.started": "2022-10-24T09:23:02.181049Z"
        },
        "id": "3v2z0oFcRjrF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get the prediction and accuracy for the test dataseta\n",
        "predictions_test, acc_test = get_acc_pred(test_loader, model_nn, device)\n",
        "predictions_train, acc_train = get_acc_pred(train_loader, model_nn, device)\n",
        "predictions_valid, acc_valid = get_acc_pred(valid_loader, model_nn, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:04.131454Z",
          "iopub.status.busy": "2022-10-24T09:23:04.131289Z",
          "iopub.status.idle": "2022-10-24T09:23:04.164428Z",
          "shell.execute_reply": "2022-10-24T09:23:04.163978Z",
          "shell.execute_reply.started": "2022-10-24T09:23:04.131438Z"
        },
        "id": "vcfIlMd3FKAX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Print Test Accuracy\n",
        "print('Test accuracy', acc_test * 100)\n",
        "print('Train accuracy', acc_train * 100)\n",
        "print('Valid accuracy', acc_valid * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:04.165156Z",
          "iopub.status.busy": "2022-10-24T09:23:04.164980Z",
          "iopub.status.idle": "2022-10-24T09:23:04.194302Z",
          "shell.execute_reply": "2022-10-24T09:23:04.193768Z",
          "shell.execute_reply.started": "2022-10-24T09:23:04.165142Z"
        },
        "id": "ZXfjniBJjX3u",
        "tags": []
      },
      "outputs": [],
      "source": [
        "wandb.log({'Best_test_Acc': acc_test})\n",
        "wandb.log({'Best_train_Acc': acc_train})\n",
        "wandb.log({'Best_valid_Acc': acc_valid})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caRp4G3ov5fp"
      },
      "source": [
        "# <Font color = 'pickle'>**Confusion Matrix for Test Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZf0pSyQV32m"
      },
      "source": [
        "Now, we will make some visualizations for the predictions that we obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQH0GvxXnam"
      },
      "source": [
        "We will construct a `confusion matrix` which will help us to visualize the performance of our classification model on the test dataset as we know the true values for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:04.195041Z",
          "iopub.status.busy": "2022-10-24T09:23:04.194862Z",
          "iopub.status.idle": "2022-10-24T09:23:04.223022Z",
          "shell.execute_reply": "2022-10-24T09:23:04.222549Z",
          "shell.execute_reply.started": "2022-10-24T09:23:04.195027Z"
        },
        "id": "NaiRaPuQYYIV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get an array containing actual labels\n",
        "testing_labels = testset.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:04.223871Z",
          "iopub.status.busy": "2022-10-24T09:23:04.223671Z",
          "iopub.status.idle": "2022-10-24T09:23:04.253617Z",
          "shell.execute_reply": "2022-10-24T09:23:04.253106Z",
          "shell.execute_reply.started": "2022-10-24T09:23:04.223857Z"
        },
        "id": "wMuZ1Yl2X47z",
        "outputId": "5c22b3ff-3060-4d18-f028-c3830ec91037",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "np.unique(testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:04.254472Z",
          "iopub.status.busy": "2022-10-24T09:23:04.254315Z",
          "iopub.status.idle": "2022-10-24T09:23:04.427017Z",
          "shell.execute_reply": "2022-10-24T09:23:04.426567Z",
          "shell.execute_reply.started": "2022-10-24T09:23:04.254457Z"
        },
        "id": "lAtBZumJcuwX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Log a confusion matrix to W&B\n",
        "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(\n",
        "                        probs = None,\n",
        "                        y_true = testing_labels,\n",
        "                        preds = predictions_test.to('cpu').numpy(),\n",
        "                        class_names =['c#','java','php','javascript','android','jquery','c++','python','iphone','asp.net'])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "execution": {
          "iopub.execute_input": "2022-10-24T09:23:04.427751Z",
          "iopub.status.busy": "2022-10-24T09:23:04.427524Z",
          "iopub.status.idle": "2022-10-24T09:23:09.403139Z",
          "shell.execute_reply": "2022-10-24T09:23:09.402650Z",
          "shell.execute_reply.started": "2022-10-24T09:23:04.427738Z"
        },
        "id": "jIlsxRdPHZYa",
        "outputId": "bc1e7a96-7958-42e3-fe04-0cf28183e08f",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Best_test_Acc</td><td>▁</td></tr><tr><td>Best_train_Acc</td><td>▁</td></tr><tr><td>Best_valid_Acc</td><td>▁</td></tr><tr><td>Train Acc :</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>Train Batch Acc :</td><td>▁▄▅▄▅▄▆▅▆▆▆▆▆▆▅▆▇▆▇▇▇█▇▇▇▆▇▇▇▇▇▆▆█▇▇█▇▇█</td></tr><tr><td>Train Batch Loss  :</td><td>█▇▄▅▄▄▃▄▃▃▃▂▄▃▃▃▂▄▁▂▂▂▂▂▂▃▂▂▂▂▂▃▂▁▁▂▁▂▂▁</td></tr><tr><td>Train Loss :</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Valid Acc :</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Valid Batch Accuracy :</td><td>▂▃▁▄▅▅▃▄▅▅▅▅▅▆▄▄▇▅▄▅▅▇▆▆▆▇▅▇▅▅█▆▇▆▆▅▇▇▆▅</td></tr><tr><td>Valid Batch Loss  :</td><td>▆▆█▄▄▄▆▄▄▄▅▃▄▃▅▃▁▃▄▃▄▂▃▃▂▂▄▂▄▃▁▃▂▃▃▅▂▂▃▂</td></tr><tr><td>Valid Loss :</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best_test_Acc</td><td>0.85716</td></tr><tr><td>Best_train_Acc</td><td>0.87352</td></tr><tr><td>Best_valid_Acc</td><td>0.85112</td></tr><tr><td>Train Acc :</td><td>0.8411</td></tr><tr><td>Train Batch Acc :</td><td>0.86328</td></tr><tr><td>Train Batch Loss  :</td><td>0.47755</td></tr><tr><td>Train Loss :</td><td>0.50079</td></tr><tr><td>Valid Acc :</td><td>0.85112</td></tr><tr><td>Valid Batch Accuracy :</td><td>0.81641</td></tr><tr><td>Valid Batch Loss  :</td><td>0.45934</td></tr><tr><td>Valid Loss :</td><td>0.45344</td></tr><tr><td>epoch</td><td>19</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">Embed_2_hidden_layers</strong>: <a href=\"https://wandb.ai/kushal07/NLP_complete_example_f22/runs/18q3ppid\" target=\"_blank\">https://wandb.ai/kushal07/NLP_complete_example_f22/runs/18q3ppid</a><br/>Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221031_031124-18q3ppid/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ]
}